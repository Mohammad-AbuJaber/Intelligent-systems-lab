{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#**Case Study 3.1**\n",
    "In this case study, you will perform essential data preprocessing steps on the Penguins dataset. The dataset contains information about different species of penguins, including their physical characteristics and the region where they were observed. Your goal is to prepare the dataset for machine learning analysis. Follow these steps:\n",
    "1. Load the penguins dataset using the code snippet provided below.\n",
    "2. Perform initial data exploration to understand the dataset's structure, features, and any missing values. Summarize the dataset's statistics and gain insights into the data.\n",
    "3. Address any data quality issues, such as missing values and outliers. Decide on an appropriate strategy for handling missing data, such as imputation or removal of rows/columns.\n",
    "4. Analyze the relevance of each feature for your machine learning task by using the learned use feature selection technques.\n",
    "5. If the dataset contains categorical variables, encode them into a numerical format suitable for machine learning models.\n",
    "6. Split the dataset into training and testing subsets to evaluate the performance of your machine learning models.\n",
    "7. Scale or normalize the numerical features to ensure consistent scaling across variables.\n",
    "8. Apply suitable dimensionality reduction techniques to reduce the size of the data while preserving important information.\n",
    "9. Validate your preprocessing pipeline by training and evaluating a machine learning model, such as the Random Forest model, on the preprocessed data. Compare the results to the model trained on the raw data (before feature filtering, transformation, and reduction) to ensure that preprocessing has improved model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from seaborn import load_dataset\n",
    "\n",
    "# Step 1: Load the penguins dataset\n",
    "df = load_dataset('penguins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Display the first few rows of the DataFrame to get an initial look at the data\n",
    "print(\"First few rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     342 non-null    float64\n",
      " 3   bill_depth_mm      342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n",
      "None\n",
      "\n",
      "Summary statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>342.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>342.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.921930</td>\n",
       "      <td>17.151170</td>\n",
       "      <td>200.915205</td>\n",
       "      <td>4201.754386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.459584</td>\n",
       "      <td>1.974793</td>\n",
       "      <td>14.061714</td>\n",
       "      <td>801.954536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>32.100000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>2700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.225000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>3550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>44.450000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>4050.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.500000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>4750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.600000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>6300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n",
       "count      342.000000     342.000000         342.000000   342.000000\n",
       "mean        43.921930      17.151170         200.915205  4201.754386\n",
       "std          5.459584       1.974793          14.061714   801.954536\n",
       "min         32.100000      13.100000         172.000000  2700.000000\n",
       "25%         39.225000      15.600000         190.000000  3550.000000\n",
       "50%         44.450000      17.300000         197.000000  4050.000000\n",
       "75%         48.500000      18.700000         213.000000  4750.000000\n",
       "max         59.600000      21.500000         231.000000  6300.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"\\nDataset information:\")\n",
    "print(df.info())\n",
    "\n",
    "# Display summary statistics for numerical features\n",
    "print(\"\\nSummary statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of missing values before handling:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "species               0\n",
       "island                0\n",
       "bill_length_mm        2\n",
       "bill_depth_mm         2\n",
       "flipper_length_mm     2\n",
       "body_mass_g           2\n",
       "sex                  11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Address data quality issues - Handling missing values\n",
    "# Impute missing values using the mean for numerical features\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Display the number of missing values before handling\n",
    "print(\"\\nNumber of missing values before handling:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of missing values after handling:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "species               0\n",
       "island                0\n",
       "bill_length_mm        0\n",
       "bill_depth_mm         0\n",
       "flipper_length_mm     0\n",
       "body_mass_g           0\n",
       "sex                  11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute missing values using the mean for numerical features\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']] = imputer.fit_transform(df[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']])\n",
    "\n",
    "# Drop rows with missing categorical values (sex)\n",
    "# df = df.dropna(subset=['sex'])\n",
    "\n",
    "# Display the number of missing values after handling\n",
    "print(\"\\nNumber of missing values after handling:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of missing values after handling for 'sex' column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "species              0\n",
       "island               0\n",
       "bill_length_mm       0\n",
       "bill_depth_mm        0\n",
       "flipper_length_mm    0\n",
       "body_mass_g          0\n",
       "sex                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute missing values in the 'sex' column with the most frequent value\n",
    "imputer_sex = SimpleImputer(strategy='most_frequent')\n",
    "df['sex'].fillna(df['sex'].mode()[0], inplace=True)\n",
    "\n",
    "# Display the number of missing values after handling for the 'sex' column\n",
    "print(\"\\nNumber of missing values after handling for 'sex' column:\")\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Analyze the relevance of each feature for your machine learning task by using feature selection techniques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features:\n",
      "Index(['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g'], dtype='object')\n",
      "\n",
      "Feature importances:\n",
      "[0.37835767 0.22747959 0.31478437 0.07937837]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Deep copy the original dataframe to avoid modifying it directly\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# Label encode categorical variables and add \"_encoded\" suffix\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode 'sex'\n",
    "df_encoded['sex_encoded'] = label_encoder.fit_transform(df_encoded['sex'])\n",
    "\n",
    "# Encode 'species'\n",
    "df_encoded['species_encoded'] = label_encoder.fit_transform(df_encoded['species'])\n",
    "\n",
    "# Encode 'island'\n",
    "df_encoded['island_encoded'] = label_encoder.fit_transform(df_encoded['island'])\n",
    "\n",
    "# Drop the original categorical columns\n",
    "df_encoded.drop(['sex', 'species', 'island'], axis=1, inplace=True)\n",
    "\n",
    "# Step 5: Feature selection using ANOVA F-statistic\n",
    "selector = SelectKBest(f_classif, k=4)\n",
    "X = df_encoded.drop(['species_encoded'], axis=1)\n",
    "y = df_encoded['species_encoded']\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Display the selected features\n",
    "print(\"\\nSelected features:\")\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(selected_features)\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df_encoded[selected_features]\n",
    "y = df_encoded['species_encoded']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_before, X_test_before, y_train_before, y_test_before = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a Random Forest classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train_before, y_train_before)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = clf.feature_importances_\n",
    "print(\"\\nFeature importances:\")\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before removing outliers: (344, 7)\n",
      "Shape after removing outliers (threshold 3): (344, 7)\n",
      "Shape after removing outliers (threshold 2.5): (341, 7)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate Z-scores for each column\n",
    "z_scores = zscore(df_encoded)\n",
    "\n",
    "# Set thresholds for Z-scores to identify outliers\n",
    "threshold_3 = 3\n",
    "threshold_2_5 = 2.5\n",
    "\n",
    "# Find the indices of outliers for threshold 3\n",
    "outliers_3 = (abs(z_scores) > threshold_3).any(axis=1)\n",
    "\n",
    "# Find the indices of outliers for threshold 2.5\n",
    "outliers_2_5 = (abs(z_scores) > threshold_2_5).any(axis=1)\n",
    "\n",
    "# Remove outliers from the dataframe for both thresholds\n",
    "df_no_outliers_3 = df_encoded[~outliers_3]\n",
    "df_no_outliers_2_5 = df_encoded[~outliers_2_5]\n",
    "\n",
    "# Display the shape before and after removing outliers for both thresholds\n",
    "print(f\"Shape before removing outliers: {df_encoded.shape}\")\n",
    "print(f\"Shape after removing outliers (threshold 3): {df_no_outliers_3.shape}\")\n",
    "print(f\"Shape after removing outliers (threshold 2.5): {df_no_outliers_2_5.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5. If the dataset contains categorical variables, encode them into a numerical format suitable for\n",
    "machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the \"species\" and \"sex\" columns\n",
    "df['species_encoded'] = label_encoder.fit_transform(df['species'])\n",
    "df['sex_encoded'] = label_encoder.fit_transform(df['sex'])\n",
    "\n",
    "# Drop the original categorical columns\n",
    "df.drop(['species', 'sex'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>species_encoded</th>\n",
       "      <th>sex_encoded</th>\n",
       "      <th>island_Biscoe</th>\n",
       "      <th>island_Dream</th>\n",
       "      <th>island_Torgersen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.10000</td>\n",
       "      <td>18.70000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>3750.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.50000</td>\n",
       "      <td>17.40000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>3800.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.30000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.92193</td>\n",
       "      <td>17.15117</td>\n",
       "      <td>200.915205</td>\n",
       "      <td>4201.754386</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.70000</td>\n",
       "      <td>19.30000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "0        39.10000       18.70000         181.000000  3750.000000   \n",
       "1        39.50000       17.40000         186.000000  3800.000000   \n",
       "2        40.30000       18.00000         195.000000  3250.000000   \n",
       "3        43.92193       17.15117         200.915205  4201.754386   \n",
       "4        36.70000       19.30000         193.000000  3450.000000   \n",
       "\n",
       "   species_encoded  sex_encoded  island_Biscoe  island_Dream  island_Torgersen  \n",
       "0                0            1          False         False              True  \n",
       "1                0            0          False         False              True  \n",
       "2                0            0          False         False              True  \n",
       "3                0            1          False         False              True  \n",
       "4                0            0          False         False              True  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use the pandas get_dummies function to perform One-Hot Encoding for \"island\"\n",
    "df = pd.get_dummies(df, columns=['island'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>species_encoded</th>\n",
       "      <th>sex_encoded</th>\n",
       "      <th>island_Biscoe</th>\n",
       "      <th>island_Dream</th>\n",
       "      <th>island_Torgersen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>43.92193</td>\n",
       "      <td>17.15117</td>\n",
       "      <td>200.915205</td>\n",
       "      <td>4201.754386</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>46.80000</td>\n",
       "      <td>14.30000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>4850.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>50.40000</td>\n",
       "      <td>15.70000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>5750.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>45.20000</td>\n",
       "      <td>14.80000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>5200.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>49.90000</td>\n",
       "      <td>16.10000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "339        43.92193       17.15117         200.915205  4201.754386   \n",
       "340        46.80000       14.30000         215.000000  4850.000000   \n",
       "341        50.40000       15.70000         222.000000  5750.000000   \n",
       "342        45.20000       14.80000         212.000000  5200.000000   \n",
       "343        49.90000       16.10000         213.000000  5400.000000   \n",
       "\n",
       "     species_encoded  sex_encoded  island_Biscoe  island_Dream  \\\n",
       "339                2            1           True         False   \n",
       "340                2            0           True         False   \n",
       "341                2            1           True         False   \n",
       "342                2            0           True         False   \n",
       "343                2            1           True         False   \n",
       "\n",
       "     island_Torgersen  \n",
       "339             False  \n",
       "340             False  \n",
       "341             False  \n",
       "342             False  \n",
       "343             False  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6. Split the dataset into training and testing subsets to evaluate the performance of your machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original features: 8\n",
      "Number of training samples: 275\n",
      "Number of testing samples: 69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define your features (X) and target variable (y)\n",
    "X = df.drop('species_encoded', axis=1)  # Features\n",
    "y = df['species_encoded']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets (e.g., 80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Number of original features: {X_train.shape[1]}\")\n",
    "print(f\"Number of training samples: {X_train.shape[0]}\")\n",
    "print(f\"Number of testing samples: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7. Scale or normalize the numerical features to ensure consistent scaling across variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>species_encoded</th>\n",
       "      <th>sex_encoded</th>\n",
       "      <th>island_Biscoe</th>\n",
       "      <th>island_Dream</th>\n",
       "      <th>island_Torgersen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.269091</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.298182</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.389831</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.429888</td>\n",
       "      <td>0.482282</td>\n",
       "      <td>0.490088</td>\n",
       "      <td>0.417154</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.167273</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "0        0.254545       0.666667           0.152542     0.291667   \n",
       "1        0.269091       0.511905           0.237288     0.305556   \n",
       "2        0.298182       0.583333           0.389831     0.152778   \n",
       "3        0.429888       0.482282           0.490088     0.417154   \n",
       "4        0.167273       0.738095           0.355932     0.208333   \n",
       "\n",
       "   species_encoded  sex_encoded  island_Biscoe  island_Dream  island_Torgersen  \n",
       "0                0            1          False         False              True  \n",
       "1                0            0          False         False              True  \n",
       "2                0            0          False         False              True  \n",
       "3                0            1          False         False              True  \n",
       "4                0            0          False         False              True  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Assuming X_train and X_test are the training and testing feature sets\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df[selected_features] = scaler.fit_transform(df[selected_features])\n",
    "\n",
    "# Display the first few rows of the DataFrame after scaling\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8\n",
    "applying suitable dimensionality reduction techniques. One commonly used technique is Principal Component Analysis (PCA). PCA can help reduce the dimensionality of the dataset while preserving important information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio for each PCA component: [9.99892104e-01 7.86782314e-05 2.47119002e-05 3.81526547e-06\n",
      " 3.08365643e-07 2.15068903e-07]\n",
      "Number of original features: 8\n",
      "Number of features retained after PCA: 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train a Random Forest model on the original data\n",
    "original_clf = RandomForestClassifier(random_state=42)\n",
    "original_clf.fit(X_train_before, y_train_before)\n",
    "\n",
    "# Make predictions on the test data\n",
    "original_y_pred = original_clf.predict(X_test_before)\n",
    "\n",
    "# Evaluate the model's performance on the original data\n",
    "original_accuracy = accuracy_score(y_test_before, original_y_pred)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=6)  # Specify the number of components\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Train a classifier on the retained PCA components and evaluate\n",
    "pca_clf = RandomForestClassifier(random_state=42)\n",
    "pca_clf.fit(X_train_pca, y_train)\n",
    "pca_y_pred = pca_clf.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the model's performance after PCA\n",
    "accuracy_after_pca = accuracy_score(y_test, pca_y_pred)\n",
    "\n",
    "# Print key metrics\n",
    "print(f\"Explained variance ratio for each PCA component: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Number of original features: {X_train.shape[1]}\")\n",
    "print(f\"Number of features retained after PCA: {X_train_pca.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Validate your preprocessing pipeline by training and evaluating a machine learning model, such as the Random Forest model, on the preprocessed data. Compare the results to the model trained on the raw data (before feature filtering, transformation, and reduction) to ensure that preprocessing has improved model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before preprocessing: 0.9710144927536232\n",
      "Accuracy after preprocessing: 0.9855072463768116\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "df = load_dataset('penguins')\n",
    "\n",
    "# train a Random Forest classifier on the original data without any preprocessing\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_before, y_train_before)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = clf.predict(X_test_before)\n",
    "\n",
    "# evaluate the model's performance on the original data\n",
    "accuracy = accuracy_score(y_test_before, y_pred)\n",
    "print(f\"Accuracy before preprocessing: {accuracy}\")\n",
    "print(f\"Accuracy after preprocessing: {accuracy_after_pca}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
